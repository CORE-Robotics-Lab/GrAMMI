{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-2.0033, grad_fn=<SumBackward0>)\n",
      "tensor([[ 1.5410, -0.2934, -2.1788]], requires_grad=True) tensor([1])\n",
      "tensor([[-0.1689, -2.0033, -3.8886]], grad_fn=<LogBackward0>)\n",
      "tensor(2.0033, grad_fn=<NllLossBackward0>)\n",
      "tensor([[ 0.9928, -0.1932, -0.3090,  0.5026, -0.8594],\n",
      "        [ 0.7502, -0.1577,  1.4437,  0.2660,  0.1665],\n",
      "        [ 0.8744, -0.1435, -0.1116, -0.6136,  1.2590],\n",
      "        [ 2.0050,  0.0537,  0.6181, -0.4128, -0.8411]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "softmax = nn.Softmax(dim=1)\n",
    "\n",
    "logits = torch.randn(1, 3, requires_grad=True)\n",
    "probs = softmax(logits)\n",
    "labels = torch.empty(1, dtype=torch.long).random_(3)\n",
    "labels_one_hot = torch.tensor([[0, 1, 0]], dtype=torch.long)\n",
    "\n",
    "print((torch.log(probs) * labels_one_hot).sum())\n",
    "\n",
    "print(logits, labels)\n",
    "print(torch.log(probs))\n",
    "# print(torch.log(probs)[1] * probs)\n",
    "\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "print(ce_loss(logits, labels))\n",
    "\n",
    "# print(logits, labels)\n",
    "\n",
    "\n",
    "################ embeddings\n",
    "# Define the number of categories and the number of dimensions for the embedding\n",
    "num_categories = 10\n",
    "embedding_dim = 5\n",
    "\n",
    "# Define the embedding layer\n",
    "embedding = nn.Embedding(num_categories, embedding_dim)\n",
    "\n",
    "# Define the input as a PyTorch tensor of longs\n",
    "input = torch.tensor([2, 3, 4, 5], dtype=torch.long)\n",
    "\n",
    "# Pass the input through the embedding layer\n",
    "output = embedding(input)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([939, 542])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "path = '/data/manisha/datasets/fixed_policy/corner_start_fixed_hideouts/train'\n",
    "\n",
    "# list of all files in the directory\n",
    "files = sorted(os.listdir(path))\n",
    "i = 20\n",
    "file = np.load(os.path.join(path, files[i]), allow_pickle=True)\n",
    "file['red_locations'][-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'random_sampler'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/nethome/sye40/PrisonerEscape/datasets/dataset_loader.ipynb Cell 1'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blandru.cc.gatech.edu/nethome/sye40/PrisonerEscape/datasets/dataset_loader.ipynb#ch0000000vscode-remote?line=13'>14</a>\u001b[0m data \u001b[39m=\u001b[39m [\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m6\u001b[39m, \u001b[39m7\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m9\u001b[39m, \u001b[39m10\u001b[39m, \u001b[39m11\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blandru.cc.gatech.edu/nethome/sye40/PrisonerEscape/datasets/dataset_loader.ipynb#ch0000000vscode-remote?line=15'>16</a>\u001b[0m map_dataset \u001b[39m=\u001b[39m MyMapDataset(data)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Blandru.cc.gatech.edu/nethome/sye40/PrisonerEscape/datasets/dataset_loader.ipynb#ch0000000vscode-remote?line=16'>17</a>\u001b[0m loader \u001b[39m=\u001b[39m DataLoader(map_dataset, batch_size\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m, random_sampler\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blandru.cc.gatech.edu/nethome/sye40/PrisonerEscape/datasets/dataset_loader.ipynb#ch0000000vscode-remote?line=18'>19</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m loader:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blandru.cc.gatech.edu/nethome/sye40/PrisonerEscape/datasets/dataset_loader.ipynb#ch0000000vscode-remote?line=19'>20</a>\u001b[0m     \u001b[39mprint\u001b[39m(batch)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'random_sampler'"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, IterableDataset, DataLoader\n",
    "\n",
    "class MyMapDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "from itertools import islice\n",
    "data = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "\n",
    "map_dataset = MyMapDataset(data)\n",
    "loader = DataLoader(map_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "for batch in loader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_known_cameras': 55, 'num_unknown_cameras': 26, 'num_helicopters': 1, 'num_search_parties': 5}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "agents = [15, 1, 5]\n",
    "x = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "y = np.repeat(x, agents, axis=0)\n",
    "z = np.repeat(np.expand_dims(y, 0), 15, axis=0)\n",
    "# print(z.shape)\n",
    "\n",
    "a = np.random.rand(15, 21, 3)\n",
    "# print(a.shape)\n",
    "\n",
    "res = np.concatenate([a, z], axis=2)\n",
    "# print(res.shape)\n",
    "\n",
    "# print(res)\n",
    "\n",
    "alpha = np.load(\"/nethome/sye40/PrisonerEscape/datasets/small_train/seed_0_known_27_unknown_26.npz\", allow_pickle=True)\n",
    "print(alpha[\"agent_dict\"].item())\n",
    "# a = np.array([, , 1])\n",
    "# b = np.zeros((a.size, a.max()+1))\n",
    "# b[np.arange(a.size),a] = 1\n",
    "# print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4)\n",
      "(3, 2)\n",
      "(3, 4, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([[0, 1, 0, 0], [0, 1, 1, 0], [0, 0, 0, 0]]) # timesteps x agents\n",
    "locs = np.array([[2, 2], [3, 3], [4, 4]]) # timesteps x detected_locations\n",
    "\n",
    "print(a.shape)\n",
    "print(locs.shape)\n",
    "\n",
    "# print(a * locs)\n",
    "res = np.einsum(\"ij,ik->ijk\", a, locs)\n",
    "print(res.shape)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96732\n",
      "96732\n"
     ]
    }
   ],
   "source": [
    "# test to mae sure dataloader is functioning properly\n",
    "path = \"/nethome/sye40/PrisonerEscape/datasets/train_same/gnn_map_0_run_300_eps_0.1_norm\"\n",
    "\n",
    "from datasets.dataset import GNNPrisonerDataset\n",
    "from datasets.old_gnn_dataset import LSTMGNNSequence\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "seq_len = 16\n",
    "step_length = 0\n",
    "num_heads = 1\n",
    "\n",
    "dataset_n = GNNPrisonerDataset(path, seq_len, num_heads, step_length, \n",
    "        include_current=False, \n",
    "        multi_head = False, \n",
    "        one_hot=False,\n",
    "        timestep=False, \n",
    "        detected_location=False)\n",
    "\n",
    "path_single = \"/nethome/sye40/PrisonerEscape/datasets/concatted/train.npz\"\n",
    "np_file = np.load(path_single, allow_pickle=True)\n",
    "future_step = step_length * num_heads\n",
    "dataset = LSTMGNNSequence(\n",
    "    np_file[\"agent_observations\"], \n",
    "    np_file[\"hideout_observations\"], \n",
    "    np_file[\"timestep_observations\"],\n",
    "    np_file[\"red_locations\"], \n",
    "    np_file[\"dones\"], \n",
    "    seq_len, future_step)\n",
    "\n",
    "x_n, y_n = dataset_n[0]\n",
    "x, y = dataset[0]\n",
    "\n",
    "print(len(dataset_n))\n",
    "print(len(dataset))\n",
    "\n",
    "for i in range(len(dataset_n)):\n",
    "    x_n, y_n = dataset_n[i]\n",
    "    x, y = dataset[i]\n",
    "\n",
    "    for j in range(3):\n",
    "\n",
    "        if not np.allclose(x_n[j], np.squeeze(x[j])):\n",
    "            print(i, j)\n",
    "            # print(x_n[j]), x[j]\n",
    "    # print(len(x_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96732, 83, 3)\n"
     ]
    }
   ],
   "source": [
    "# convert new format to old format\n",
    "import os\n",
    "\n",
    "total_agents = []\n",
    "total_hideouts = []\n",
    "total_timesteps = []\n",
    "total_red_locations = []\n",
    "total_dones = []\n",
    "\n",
    "# folder_path = \"/nethome/sye40/PrisonerEscape/datasets/test_same/gnn_map_0_run_100_eps_0.1_norm\"\n",
    "folder_path = \"/nethome/sye40/PrisonerEscape/datasets/train_same/gnn_map_0_run_300_eps_0.1_norm\"\n",
    "# folder_path = \"/nethome/sye40/PrisonerEscape/datasets/debug\"\n",
    "for file_name in os.listdir(folder_path):\n",
    "    np_file = np.load(os.path.join(folder_path, file_name), allow_pickle=True)\n",
    "    agent_o = np.squeeze(np_file[\"agent_observations\"])\n",
    "    hideout_o = np_file[\"hideout_observations\"]\n",
    "    t_o = np_file[\"timestep_observations\"]\n",
    "    r_o = np_file[\"red_locations\"]/2428\n",
    "    d_o = np_file[\"dones\"]\n",
    "\n",
    "    total_agents.append(agent_o)\n",
    "    total_hideouts.append(hideout_o)\n",
    "    total_timesteps.append(t_o)\n",
    "    total_red_locations.append(r_o)\n",
    "    total_dones.append(d_o)\n",
    "\n",
    "# print(np.concatenate(total_agents, axis=0).shape)\n",
    "np.savez(\"/nethome/sye40/PrisonerEscape/datasets/concatted/train.npz\", \n",
    "            agent_observations=np.concatenate(total_agents, axis=0),\n",
    "            hideout_observations=np.concatenate(total_hideouts, axis=0),\n",
    "            timestep_observations=np.concatenate(total_timesteps, axis=0),\n",
    "            red_locations=np.concatenate(total_red_locations, axis=0), \n",
    "            dones=np.concatenate(total_dones, axis=0)\n",
    "            )\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f0c3bfbc0528239c32ebf5b583237c33afb2ab3d4f242283158514eeade34da9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('prisoner_auto')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
